{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv, requests, os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from Google sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying Doc: https://docs.google.com/spreadsheets/d/1bvRKCfu9iGllHsOolDjMtbGA_2COddQFoZ7I45Lyn6o/edit#gid=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/5dzvdsg55xn25gp9vjh1f4xc0000gn/T/ipykernel_46796/3888547131.py:13: FutureWarning: Could not cast to int64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n",
      "  df = pd.DataFrame(list(reader), columns=header, dtype=int)\n",
      "/var/folders/bp/5dzvdsg55xn25gp9vjh1f4xc0000gn/T/ipykernel_46796/3888547131.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['filepath'] = 'speeches/' + df.Filename\n",
      "/var/folders/bp/5dzvdsg55xn25gp9vjh1f4xc0000gn/T/ipykernel_46796/3888547131.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['file_exists'] = df['filepath'].apply(lambda x: os.path.isfile(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>State</th>\n",
       "      <th>Governor</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Party</th>\n",
       "      <th>Type of Speech</th>\n",
       "      <th>New Gov?</th>\n",
       "      <th>2020 Contender?</th>\n",
       "      <th>Region</th>\n",
       "      <th>Trifecta Status</th>\n",
       "      <th>Trifecta</th>\n",
       "      <th>Best Transcript URL</th>\n",
       "      <th>Selector</th>\n",
       "      <th>Note</th>\n",
       "      <th>Lesser Transcript URL</th>\n",
       "      <th>New Best Transcript URL</th>\n",
       "      <th>filepath</th>\n",
       "      <th>file_exists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama_Inaugural.txt</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Kay Ivey</td>\n",
       "      <td>Female</td>\n",
       "      <td>R</td>\n",
       "      <td>Inaugural</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>South</td>\n",
       "      <td>R trifecta</td>\n",
       "      <td>Trifecta</td>\n",
       "      <td>https://governor.alabama.gov/remarks-speeches/...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.al.com/news/2019/01/the-full-text-...</td>\n",
       "      <td></td>\n",
       "      <td>speeches/Alabama_Inaugural.txt</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama_SOTS.txt</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Kay Ivey</td>\n",
       "      <td>Female</td>\n",
       "      <td>R</td>\n",
       "      <td>State of the state</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>South</td>\n",
       "      <td>R trifecta</td>\n",
       "      <td>Trifecta</td>\n",
       "      <td>https://governor.alabama.gov/remarks-speeches/...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://governor.alabama.gov/remarks-speeches/...</td>\n",
       "      <td>speeches/Alabama_SOTS.txt</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alaska_SOTS.txt</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Mike Dunleavy</td>\n",
       "      <td>Male</td>\n",
       "      <td>R</td>\n",
       "      <td>State of the state</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>West</td>\n",
       "      <td>Divided government</td>\n",
       "      <td>Divided</td>\n",
       "      <td>https://gov.alaska.gov/newsroom/2019/01/22/201...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.adn.com/politics/2019/01/23/watch-...</td>\n",
       "      <td>https://gov.alaska.gov/newsroom/2019/01/22/201...</td>\n",
       "      <td>speeches/Alaska_SOTS.txt</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arizona_Inaugural.txt</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Doug Ducey</td>\n",
       "      <td>Male</td>\n",
       "      <td>R</td>\n",
       "      <td>Inaugural</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>West</td>\n",
       "      <td>R trifecta</td>\n",
       "      <td>Trifecta</td>\n",
       "      <td>https://azgovernor.gov/governor/news/2019/01/g...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>speeches/Arizona_Inaugural.txt</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arizona_SOTS.txt</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Doug Ducey</td>\n",
       "      <td>Male</td>\n",
       "      <td>R</td>\n",
       "      <td>State of the state</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>West</td>\n",
       "      <td>R trifecta</td>\n",
       "      <td>Trifecta</td>\n",
       "      <td>https://azgovernor.gov/governor/news/2019/01/g...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://azgovernor.gov/governor/news/2019/01/g...</td>\n",
       "      <td>speeches/Arizona_SOTS.txt</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Filename    State       Governor  Gender Party  \\\n",
       "0  Alabama_Inaugural.txt  Alabama       Kay Ivey  Female     R   \n",
       "1       Alabama_SOTS.txt  Alabama       Kay Ivey  Female     R   \n",
       "3        Alaska_SOTS.txt   Alaska  Mike Dunleavy    Male     R   \n",
       "4  Arizona_Inaugural.txt  Arizona     Doug Ducey    Male     R   \n",
       "5       Arizona_SOTS.txt  Arizona     Doug Ducey    Male     R   \n",
       "\n",
       "       Type of Speech New Gov? 2020 Contender? Region     Trifecta Status  \\\n",
       "0           Inaugural       No              No  South          R trifecta   \n",
       "1  State of the state       No              No  South          R trifecta   \n",
       "3  State of the state      Yes              No   West  Divided government   \n",
       "4           Inaugural       No              No   West          R trifecta   \n",
       "5  State of the state       No              No   West          R trifecta   \n",
       "\n",
       "   Trifecta                                Best Transcript URL Selector Note  \\\n",
       "0  Trifecta  https://governor.alabama.gov/remarks-speeches/...                 \n",
       "1  Trifecta  https://governor.alabama.gov/remarks-speeches/...                 \n",
       "3   Divided  https://gov.alaska.gov/newsroom/2019/01/22/201...                 \n",
       "4  Trifecta  https://azgovernor.gov/governor/news/2019/01/g...                 \n",
       "5  Trifecta  https://azgovernor.gov/governor/news/2019/01/g...                 \n",
       "\n",
       "                               Lesser Transcript URL  \\\n",
       "0  https://www.al.com/news/2019/01/the-full-text-...   \n",
       "1                                                      \n",
       "3  https://www.adn.com/politics/2019/01/23/watch-...   \n",
       "4                                                      \n",
       "5                                                      \n",
       "\n",
       "                             New Best Transcript URL  \\\n",
       "0                                                      \n",
       "1  https://governor.alabama.gov/remarks-speeches/...   \n",
       "3  https://gov.alaska.gov/newsroom/2019/01/22/201...   \n",
       "4                                                      \n",
       "5  https://azgovernor.gov/governor/news/2019/01/g...   \n",
       "\n",
       "                         filepath  file_exists  \n",
       "0  speeches/Alabama_Inaugural.txt         True  \n",
       "1       speeches/Alabama_SOTS.txt         True  \n",
       "3        speeches/Alaska_SOTS.txt         True  \n",
       "4  speeches/Arizona_Inaugural.txt         True  \n",
       "5       speeches/Arizona_SOTS.txt         True  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_regular_gsheet_url(doc_id, sheet_id):\n",
    "    return f\"https://docs.google.com/spreadsheets/d/{doc_id}/edit#gid={sheet_id}\"\n",
    "\n",
    "def make_csv_gsheet_url(doc_id, sheet_id):\n",
    "    return f\"https://docs.google.com/spreadsheets/d/{doc_id}/export?format=csv&id={doc_id}&gid={sheet_id}\"\n",
    "\n",
    "\n",
    "GOOGLE_SHEET_ID = '1bvRKCfu9iGllHsOolDjMtbGA_2COddQFoZ7I45Lyn6o'\n",
    "print(\"Querying Doc:\", make_regular_gsheet_url(GOOGLE_SHEET_ID, \"0\"))\n",
    "response = requests.get(make_csv_gsheet_url(GOOGLE_SHEET_ID, \"0\"))\n",
    "reader = csv.reader(response.text.splitlines())\n",
    "header = next(reader)\n",
    "df = pd.DataFrame(list(reader), columns=header, dtype=int)\n",
    "\n",
    "# Remove rows when N/A is a filename\n",
    "df = df[df['Filename'] != 'N/A']\n",
    "df['filepath'] = 'speeches/' + df.Filename\n",
    "df['file_exists'] = df['filepath'].apply(lambda x: os.path.isfile(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset is 50 speeches'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['Type of Speech'].isin(['State of the state','Both'])]\n",
    "f\"Dataset is {len(df)} speeches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is 48 speeches\n"
     ]
    }
   ],
   "source": [
    "STATES_TO_WITHOLD = ['Washington', 'Utah']\n",
    "df_witheld = df.query(\"State.isin(@STATES_TO_WITHOLD)\")\n",
    "df = df.query(\"~State.isin(@STATES_TO_WITHOLD)\")\n",
    "print(f\"Dataset is {len(df)} speeches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speeches(df):\n",
    "    speeches = []\n",
    "    for path in df['filepath']:\n",
    "        with open(path) as f:\n",
    "            text = f.read()\n",
    "            speeches.append(text)\n",
    "    return speeches\n",
    "\n",
    "speeches = get_speeches(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "## YOU CAN EDIT THESE\n",
    "y_columns = ['Party', 'Trifecta']\n",
    "BINARY=False\n",
    "NGRAMS=1\n",
    "MIN_DF=3\n",
    "\n",
    "def ngram_vectorizer(n, binary, min_df):\n",
    "    return CountVectorizer(\n",
    "        stop_words='english', # 'english' if not custom list\n",
    "        ngram_range=(1,n),\n",
    "        binary=binary,\n",
    "        min_df=min_df\n",
    "    )\n",
    "\n",
    "vectorizer = ngram_vectorizer(NGRAMS, binary=BINARY, min_df=MIN_DF)\n",
    "X = vectorizer.fit_transform(speeches)\n",
    "y = np.array(df['Party'] == \"R\").astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['index_x', 'index_y'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bp/5dzvdsg55xn25gp9vjh1f4xc0000gn/T/ipykernel_46796/3717097399.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# turning it back into a dataframe for visibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'State'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Governor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Party'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Trifecta Status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'index_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4954\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4955\u001b[0m         \"\"\"\n\u001b[0;32m-> 4956\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4957\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4958\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4277\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4278\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4279\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4321\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4323\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4324\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6643\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6644\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6645\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6646\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['index_x', 'index_y'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Display X\n",
    "# turning it back into a dataframe for visibility\n",
    "word_vectors = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "x_display = df[['State', 'Governor', 'Party', 'Trifecta Status']].reset_index().\\\n",
    "    merge(word_vectors, left_index=True, right_index=True)\\\n",
    "    .drop(columns=['index_x', 'index_y']).head()\n",
    "\n",
    "print(\"X is the vector of words shown in the dataframe below\")\n",
    "display(x_display)\n",
    "print(\"1 is Republican, 0 is Democrat\")\n",
    "print(\"y=\", y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1e-10)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1.0e-10, class_prior=None, fit_prior=True)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  test_precision  test_recall  test_f1\n",
       "0       0.0         0.0           0.75            0.75         0.86     0.80\n",
       "1       0.0         0.0           0.58            0.58         1.00     0.74\n",
       "2       0.0         0.0           0.42            0.45         0.83     0.59\n",
       "3       0.0         0.0           0.67            0.60         1.00     0.75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test_accuracy     0.60\n",
       "test_precision    0.60\n",
       "test_recall       0.92\n",
       "test_f1           0.72\n",
       "dtype: float64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "\n",
    "# 5-fold cross-validation\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=4)\n",
    "display(pd.DataFrame(scores).round(2))\n",
    "\n",
    "pd.DataFrame(scores)[\n",
    "    ['test_accuracy','test_precision','test_recall','test_f1']]\\\n",
    "    .mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Washington', 'Utah']\n"
     ]
    }
   ],
   "source": [
    "print(STATES_TO_WITHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "witheld_speeches = get_speeches(df_witheld)\n",
    "# print(witheld_speeches[0])\n",
    "# print(witheld_speeches[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x11118 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1574 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_witheld_states = vectorizer.transform(witheld_speeches)\n",
    "X_witheld_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>Washington_x</th>\n",
       "      <th>Utah_x</th>\n",
       "      <th>index_y</th>\n",
       "      <th>Washington_y</th>\n",
       "      <th>Utah_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>state</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>state</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tax</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>washington</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>utah</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>people</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>let</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>story</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>year</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>new</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>education</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>health</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>new</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>ve</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>economy</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>chapter</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>day</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>education</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>challenges</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>today</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index_x  Washington_x  Utah_x     index_y  Washington_y  Utah_y\n",
       "0       state            27      34       state            27      34\n",
       "1         tax            22       0  washington             1      19\n",
       "2        utah            22       0      people             3      17\n",
       "3         let            16       3       story             0      16\n",
       "4        year            14       5         new            10      15\n",
       "5   education            10       8      health             2      12\n",
       "6         new            10      15          ve             0      11\n",
       "7     economy             9       1     chapter             0       9\n",
       "8         day             9       3   education            10       8\n",
       "9  challenges             9       3       today             5       8"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "witheld_states_word_vectors = pd.DataFrame(X_witheld_states.toarray(), \n",
    "                            columns=vectorizer.get_feature_names_out(),\n",
    "                            index=STATES_TO_WITHOLD)\n",
    "\n",
    "\n",
    "washington_top_words = witheld_states_word_vectors.T.sort_values(by='Washington', ascending=False).head(25)\n",
    "utah_top_words = witheld_states_word_vectors.T.sort_values(by='Utah', ascending=False).head(25)\n",
    "\n",
    "washington_top_words.reset_index().merge(utah_top_words.reset_index(), left_index=True, right_index=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_witheld_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.56696827e-029, 1.00000000e+000],\n",
       "       [1.00000000e+000, 3.82858217e-147]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_witheld_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -64.51665134,    0.        ],\n",
       "       [   0.        , -337.13751413]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_log_proba(X_witheld_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
